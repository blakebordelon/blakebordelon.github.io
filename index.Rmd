---
title: ""
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


<div class = "row">
<div class = "col-md-5">
<br><br>
![A recent picture of me](IMG_1952.jpg){width=100%}
</div>
<div class = "col-md-6">
<br><br>
I am an applied math PhD student in the [Pehlevan Group](https://pehlevan.seas.harvard.edu/) at Harvard. My research interests lie in the convex hull of machine learning, statistical physics, and theoretical neuroscience. Before graduate school, I studied physics, engineering, and computer science at [Washington University in St. Louis](https://wustl.edu/). 

My works can be found on [Google Scholar](https://scholar.google.com/citations?user=yeQ8_pgAAAAJ&hl=en). I also occasionally post new preprints on [twitter](https://twitter.com/blake__bordelon).

<br><br>
</div>
<br><br>
</div>
### Recent News
+ Papers to appear at Neurips 2023 on (1) [finite width corrections to the DMFT limit](https://openreview.net/forum?id=fKwG6grp8o), (2) empirical study of [convergence to infinite width feature learning limit](https://openreview.net/forum?id=LTdfYIvbHc) and (3) the loss dynamics of [temporal difference learning in high dimension](https://openreview.net/forum?id=Tj0eXVPnRX).
+ We will be giving a presentation on ["Deptwise Hyperparameter Transfer in ResNets"](https://arxiv.org/abs/2309.16620) at the ["M3L"](https://sites.google.com/view/m3l-2023/home) workshop at Neurips.
+ Our work on [dynamical mean field theory for feature learning](https://iopscience.iop.org/article/10.1088/1742-5468/ad01b0) was chosen for the JSTAT special issue on Machine Learning. 
 


### Reviewed Publications

- **Bordelon**, Pehlevan ["Dynamics of Finite Width Kernel and Prediction Fluctuations in Mean Field Neural Networks"](https://openreview.net/forum?id=fKwG6grp8o), *Neurips* spotlight 2023.
 
- **Bordelon**, Masset, Kuo, Pehlevan ["Loss Dynamics of Temporal Difference Reinforcement Learning"](https://openreview.net/forum?id=Tj0eXVPnRX), *Neurips* 2023.

- Vyas, Atanasov, **Bordelon**, Morwani, Sainathan, Pehlevan [Feature-Learning Networks are consistent across widths at realistic scales](https://openreview.net/forum?id=LTdfYIvbHc) *Neurips* 2023 (equal contribution of first three authors).


- **Bordelon**, Pehlevan ["The Influence of Learning Rule on Representation Dynamics in Wide Neural Networks"](https://openreview.net/forum?id=nZ2NtpolC5-), *ICLR* 2023. Notable-top 25%.

- Atanasov, **Bordelon**, Sainathan, Pehlevan [The Onset of Variance-Limited Behavior for Networks in the Lazy and Rich Regimes](https://openreview.net/forum?id=JLINxPOVTh7) (Equal Contribution), *ICLR* 2023. 

- **Bordelon**, Pehlevan ["Population Codes Enable Learning from Few Examples By Shaping Inductive Bias"](https://elifesciences.org/articles/78606), *Elife* 2022.

- **Bordelon**, Pehlevan [Self-consistent Dynamical Field Theory of Kernel Evolution in Wide Neural Networks](https://openreview.net/forum?id=sipwrPCrIS). *Neurips* 2022. 

- Atanasov, **Bordelon**, Pehlevan ["Neural Networks as Kernel Learners: The Silent Alignment Effect"](https://arxiv.org/abs/2111.00034) (Equal Contribution), *ICLR* 2022.

- Farrell, **Bordelon**, Trivedi, Pehlevan ["Capacity of Group-invariant Linear Readouts from Equivariant Representations: How Many Objects can be Linearly Classified Under All Possible Views?"](https://arxiv.org/abs/2110.07472) (Equal Contribution), *ICLR* 2022.

- **Bordelon**, Pehlevan ["Learning Curves for SGD on Structured Features
"](https://openreview.net/forum?id=WPI2vbkAl3Q), *ICLR* 2022.

- Canatar, **Bordelon**, Pehlevan ["Out-of-Distribution Generalization in Kernel Regression"](https://arxiv.org/abs/2106.02261), *Neurips* 2021.

- Canatar, **Bordelon**, and Pehlevan, [“Spectral bias and task-model alignment explain generalization in kernel regression and infinitely wide neural networks”](https://www.nature.com/articles/s41467-021-23103-1) *Nature Communications* 2021. 

- **Bordelon**, Canatar, and Pehlevan, [“Spectrum Dependent Learning Curves in Kernel Regression and Wide Neural Networks,”](https://arxiv.org/abs/2002.02561) *ICML*, 2020.

- Atkinson, Mahzoon, Keim, **Bordelon**, Pruitt, Charity, and Dickhoff [“Dispersive optical model analysis of Pb-208 generating a neutron-skin prediction beyond the mean field,”](https://journals.aps.org/prc/abstract/10.1103/PhysRevC.101.044303)
*Phys. Rev. C* 101, 044303, 2020

- Bagley, **Bordelon**, Moseley, Wessel ["Pre-Synaptic Pool Modification (PSPM): A supervised learning procedure for recurrent spiking neural networks""](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0229083) *PLOS ONE*, 2020. 


### Preprints

- **Bordelon**, Noci, Li, Hanin, Pehlevan. ["Depthwise Hyperparameter Transfer in Residual Networks: Dynamics and Scaling Limit"](https://arxiv.org/abs/2309.16620) 2023. 

- Kumar, **Bordelon**, Gershman, Pehlevan ["Grokking as the Transition from Lazy to Rich Training Dynamics"](https://arxiv.org/abs/2310.06110) 2023.

- Shan, **Bordelon** ["Rapid Feature Evolution Accelerates Learning in Neural Networks
"](https://arxiv.org/abs/2105.14301) (Equal Contribution) 2021.





